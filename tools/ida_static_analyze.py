#!/usr/bin/env python3
"""
IDA Static Analysis Pipeline for Stripped Binaries (v2 - Audit Grade)

Auditable static analysis using IDA Pro batch mode.
Produces: run_summary.md, findings.json, evidence.md, database.i64, pseudocode.c

Usage:
    python3 tools/ida_static_analyze.py <binary_path> [--ida-path <path>] [--debug]

Example:
    python3 tools/ida_static_analyze.py test_binaries/vuln2_stripped --debug
"""

import argparse
import hashlib
import json
import os
import shutil
import subprocess
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Optional

# Configuration
DEFAULT_IDA_PATH = "/mnt/c/Users/ChemistryKing/Desktop/IDA Professional 9.0/idat64.exe"
WINDOWS_TEMP_BASE = "/mnt/c/temp/ida_static_analysis"


def wsl_to_windows_path(wsl_path: str) -> str:
    """Convert WSL path to Windows path."""
    wsl_path = os.path.abspath(wsl_path)
    if wsl_path.startswith("/mnt/"):
        parts = wsl_path[5:].split("/", 1)
        drive = parts[0].upper()
        rest = parts[1].replace("/", "\\") if len(parts) > 1 else ""
        return f"{drive}:\\{rest}"
    return wsl_path


def compute_sha256(file_path: str) -> str:
    """Compute SHA256 hash of a file."""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256_hash.update(chunk)
    return sha256_hash.hexdigest()


def generate_ida_script(
    run_id: str,
    windows_temp_dir: str,
    binary_name: str,
) -> str:
    """Generate the IDAPython script for comprehensive analysis."""

    # Escape backslashes for Python string
    windows_temp_escaped = windows_temp_dir.replace("\\", "\\\\")

    script = f'''# IDAPython Static Analysis Script - {run_id}
# Auto-generated by ida_static_analyze.py (v2 - Audit Grade)
# Target: {binary_name}

import json
import os
import re
import sys
import traceback
from datetime import datetime

import idc
import idaapi
import idautils
import ida_funcs
import ida_bytes
import ida_name
import ida_xref
import ida_ida
import ida_segment
import ida_lines
import ida_pro
import ida_typeinf
import ida_nalt
import ida_loader

# Try to import Hex-Rays
HAS_HEXRAYS = False
cfunc_cache = {{}}  # func_ea -> cfunc object
try:
    import ida_hexrays
    if ida_hexrays.init_hexrays_plugin():
        HAS_HEXRAYS = True
        print("[DECOMP] Hex-Rays available: yes")
    else:
        print("[DECOMP] Hex-Rays available: no (init failed)")
except ImportError:
    print("[DECOMP] Hex-Rays available: no (not installed)")

# Wait for auto-analysis
print("[STAGE] Waiting for IDA auto-analysis...")
idaapi.auto_wait()
print("[STAGE] Auto-analysis complete")

# Output paths
OUTPUT_DIR = r"{windows_temp_escaped}"
FINDINGS_JSON = os.path.join(OUTPUT_DIR, "findings.json")
EVIDENCE_MD = os.path.join(OUTPUT_DIR, "evidence.md")
PSEUDOCODE_C = os.path.join(OUTPUT_DIR, "pseudocode.c")
IDA_LOG = os.path.join(OUTPUT_DIR, "ida_batch.log")

# Libc function prototypes for type recovery
LIBC_PROTOTYPES = {{
    "malloc": "void *malloc(size_t size);",
    "_malloc": "void *malloc(size_t size);",
    "calloc": "void *calloc(size_t nmemb, size_t size);",
    "_calloc": "void *calloc(size_t nmemb, size_t size);",
    "realloc": "void *realloc(void *ptr, size_t size);",
    "_realloc": "void *realloc(void *ptr, size_t size);",
    "free": "void free(void *ptr);",
    "_free": "void free(void *ptr);",
    "strcpy": "char *strcpy(char *dest, const char *src);",
    "_strcpy": "char *strcpy(char *dest, const char *src);",
    "__strcpy_chk": "char *__strcpy_chk(char *dest, const char *src, size_t destlen);",
    "___strcpy_chk": "char *__strcpy_chk(char *dest, const char *src, size_t destlen);",
    "strcat": "char *strcat(char *dest, const char *src);",
    "_strcat": "char *strcat(char *dest, const char *src);",
    "strncpy": "char *strncpy(char *dest, const char *src, size_t n);",
    "_strncpy": "char *strncpy(char *dest, const char *src, size_t n);",
    "memcpy": "void *memcpy(void *dest, const void *src, size_t n);",
    "_memcpy": "void *memcpy(void *dest, const void *src, size_t n);",
    "memmove": "void *memmove(void *dest, const void *src, size_t n);",
    "_memmove": "void *memmove(void *dest, const void *src, size_t n);",
    "printf": "int printf(const char *format, ...);",
    "_printf": "int printf(const char *format, ...);",
    "__printf_chk": "int __printf_chk(int flag, const char *format, ...);",
    "___printf_chk": "int __printf_chk(int flag, const char *format, ...);",
    "sprintf": "int sprintf(char *str, const char *format, ...);",
    "_sprintf": "int sprintf(char *str, const char *format, ...);",
    "snprintf": "int snprintf(char *str, size_t size, const char *format, ...);",
    "_snprintf": "int snprintf(char *str, size_t size, const char *format, ...);",
    "fopen": "FILE *fopen(const char *pathname, const char *mode);",
    "_fopen": "FILE *fopen(const char *pathname, const char *mode);",
    "fread": "size_t fread(void *ptr, size_t size, size_t nmemb, FILE *stream);",
    "_fread": "size_t fread(void *ptr, size_t size, size_t nmemb, FILE *stream);",
    "read": "ssize_t read(int fd, void *buf, size_t count);",
    "_read": "ssize_t read(int fd, void *buf, size_t count);",
    "gets": "char *gets(char *s);",
    "_gets": "char *gets(char *s);",
    "fgets": "char *fgets(char *s, int size, FILE *stream);",
    "_fgets": "char *fgets(char *s, int size, FILE *stream);",
    "strlen": "size_t strlen(const char *s);",
    "_strlen": "size_t strlen(const char *s);",
    "strcmp": "int strcmp(const char *s1, const char *s2);",
    "_strcmp": "int strcmp(const char *s1, const char *s2);",
    "sscanf": "int sscanf(const char *str, const char *format, ...);",
    "_sscanf": "int sscanf(const char *str, const char *format, ...);",
    "__isoc99_sscanf": "int sscanf(const char *str, const char *format, ...);",
}}

# Dangerous function patterns
DANGEROUS_SINKS = {{
    # Buffer overflow / unsafe copy
    "strcpy": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-121"], "category": "copy", "confidence": "confirmed"}},
    "strcat": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-121"], "category": "copy", "confidence": "confirmed"}},
    "sprintf": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-134"], "category": "format", "confidence": "confirmed"}},
    "gets": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-242"], "category": "input", "confidence": "confirmed"}},
    "scanf": {{"type": "BufferOverflow", "cwe": ["CWE-120"], "category": "input", "confidence": "likely"}},
    "memcpy": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-122"], "category": "copy", "confidence": "likely"}},
    "memmove": {{"type": "BufferOverflow", "cwe": ["CWE-120", "CWE-122"], "category": "copy", "confidence": "likely"}},

    # Format string
    "printf": {{"type": "FormatString", "cwe": ["CWE-134"], "category": "format", "confidence": "likely"}},
    "fprintf": {{"type": "FormatString", "cwe": ["CWE-134"], "category": "format", "confidence": "likely"}},
    "syslog": {{"type": "FormatString", "cwe": ["CWE-134"], "category": "format", "confidence": "likely"}},
    "snprintf": {{"type": "FormatString", "cwe": ["CWE-134"], "category": "format", "confidence": "possible"}},

    # Heap/memory (for UAF and integer overflow detection)
    "malloc": {{"type": "HeapAlloc", "cwe": ["CWE-190"], "category": "alloc", "confidence": "possible"}},
    "calloc": {{"type": "HeapAlloc", "cwe": ["CWE-190"], "category": "alloc", "confidence": "possible"}},
    "realloc": {{"type": "HeapAlloc", "cwe": ["CWE-190"], "category": "alloc", "confidence": "possible"}},
    "free": {{"type": "FreeSite", "cwe": ["CWE-416"], "category": "free", "confidence": "info"}},
}}

# Variable naming heuristics
VAR_NAMING_PATTERNS = {{
    "size": ["size", "sz", "len", "length", "count", "n", "num"],
    "buffer": ["buf", "buffer", "ptr", "data", "dest", "dst"],
    "source": ["src", "source", "in", "input"],
    "path": ["path", "filename", "fname", "file"],
    "format": ["fmt", "format"],
}}

# Analysis state
analysis_log = []
raw_candidates = []
dedup_findings = []
free_sites = {{}}  # func_ea -> [(free_ea, ptr_reg_or_loc)]
comment_sites = []  # Track all comments written
type_changes = []  # Track type/rename changes

def log(msg: str, level: str = "INFO"):
    \"\"\"Log a message with timestamp.\"\"\"
    ts = datetime.now().strftime("%H:%M:%S")
    line = f"[{{ts}}] [{{level}}] {{msg}}"
    print(line, flush=True)
    analysis_log.append(line)

def get_basic_info() -> dict:
    \"\"\"Get basic binary information.\"\"\"
    return {{
        "input_file": idc.get_input_file_path(),
        "file_type": idaapi.get_file_type_name(),
        "processor": idaapi.get_idp_name(),
        "bits": 64 if ida_ida.inf_is_64bit() else 32,
        "entry_point": hex(ida_ida.inf_get_start_ea()),
        "is_stripped": True,
    }}

def apply_libc_prototypes():
    \"\"\"Apply known prototypes to libc functions for better type recovery.\"\"\"
    log("[STAGE] Applying libc function prototypes...")
    applied_count = 0

    til = ida_typeinf.get_idati()

    for ea, name in idautils.Names():
        # Clean the name (remove leading underscores for matching)
        clean_name = name.lstrip("_")

        # Check if we have a prototype for this function
        for func_name, proto in LIBC_PROTOTYPES.items():
            if clean_name == func_name.lstrip("_") or name == func_name:
                try:
                    # Try to apply the type
                    tif = ida_typeinf.tinfo_t()
                    if ida_typeinf.parse_decl(tif, til, proto, ida_typeinf.PT_SIL):
                        if ida_typeinf.apply_tinfo(ea, tif, ida_typeinf.TINFO_DEFINITE):
                            log(f"[TYPE] Applied prototype to {{name}}: {{proto.split('(')[0].split()[-1]}}")
                            type_changes.append({{
                                "type": "prototype",
                                "address": hex(ea),
                                "name": name,
                                "proto": proto.split(";")[0]
                            }})
                            applied_count += 1
                except Exception as e:
                    pass  # Silently skip failures
                break

    log(f"[TYPE] Applied {{applied_count}} function prototypes")
    return applied_count

def get_cfunc(func_ea: int):
    \"\"\"Get or cache the decompiled cfunc for a function.\"\"\"
    if not HAS_HEXRAYS:
        return None

    if func_ea in cfunc_cache:
        return cfunc_cache[func_ea]

    try:
        cfunc = ida_hexrays.decompile(func_ea)
        if cfunc:
            cfunc_cache[func_ea] = cfunc
            log(f"[DECOMP] Success for func@{{hex(func_ea)}}")
            return cfunc
        else:
            log(f"[DECOMP] Failed for func@{{hex(func_ea)}}: returned None")
            return None
    except Exception as e:
        log(f"[DECOMP] Failed for func@{{hex(func_ea)}}: {{str(e)}}")
        return None

def extract_call_args_from_disasm(target_ea: int) -> dict:
    \"\"\"Extract information about call arguments from disassembly context.

    Returns dict with: size_expr (for malloc), arg_values (literal values), has_add_16, etc.
    \"\"\"
    info = {{
        "size_add_16": False,  # malloc(x + 16)
        "size_from_ptr": False,  # malloc(*ptr)
        "arg_values": [],  # Immediate values like 0x40, 0x3B
        "arg3_value": None,  # Third argument for strcpy_chk
    }}

    # Scan backward for argument setup
    ea = target_ea
    for _ in range(10):
        ea = idc.prev_head(ea)
        if ea == idc.BADADDR:
            break

        disasm = idc.generate_disasm_line(ea, 0).lower()

        # Check for add with 0x10/16
        if "add" in disasm and ("10h" in disasm or ", 16" in disasm or ", 0x10" in disasm):
            if "rdi" in disasm or "edi" in disasm:
                info["size_add_16"] = True

        # Check for loading from pointer (mov edi, [rax])
        if "mov" in disasm and ("edi" in disasm or "rdi" in disasm) and "[" in disasm:
            info["size_from_ptr"] = True

        # Check for immediate values in edx (3rd arg)
        if "mov" in disasm and ("edx" in disasm or "rdx" in disasm):
            import re
            match = re.search(r',\\s*([0-9A-Fa-f]+)h?\\b', disasm)
            if match:
                try:
                    val = int(match.group(1).rstrip('h'), 16)
                    info["arg_values"].append(val)
                    if "edx" in disasm:
                        info["arg3_value"] = val
                except:
                    pass

    return info

def disambiguate_callee_line(lines: list, candidate_lines: list, callee: str, call_info: dict) -> int:
    \"\"\"Choose the correct line from multiple candidates based on call context.\"\"\"

    log(f"[DECOMP] Disambiguating {{len(candidate_lines)}} candidates for {{callee}}: add16={{call_info.get('size_add_16')}}, ptr={{call_info.get('size_from_ptr')}}, arg3={{call_info.get('arg3_value')}}")

    for line_idx in candidate_lines:
        line = lines[line_idx].lower()

        # For malloc with add 16 pattern
        if callee == "malloc" and call_info.get("size_add_16"):
            if "+ 16" in line or "+16" in line or "+ 0x10" in line:
                log(f"[DECOMP] Matched line {{line_idx}} by +16 pattern")
                return line_idx

        # For malloc with ptr dereference pattern
        if callee == "malloc" and call_info.get("size_from_ptr"):
            if "*" in line and "malloc" in line:
                # Check if it's dereferencing (e.g., malloc(*ptr + 16))
                if "(*" in line or "* " in line:
                    log(f"[DECOMP] Matched line {{line_idx}} by ptr deref pattern")
                    return line_idx

        # For strcpy_chk with specific arg3 value
        if "strcpy" in callee and call_info.get("arg3_value"):
            arg3 = call_info["arg3_value"]
            # Look for the hex value in the line
            if f"0x{{arg3:x}}" in line or f"{{arg3}}" in line:
                log(f"[DECOMP] Matched line {{line_idx}} by arg3={{arg3}} (0x{{arg3:x}})")
                return line_idx

    # No match found
    log(f"[DECOMP] No disambiguation match found")
    return -1

def get_pseudocode_at_address(func_ea: int, target_ea: int, context_lines: int = 10, finding_id: str = "?") -> str:
    \"\"\"Extract pseudocode snippet centered on a specific address.

    Uses Hex-Rays ctree EA matching for reliable sink->line mapping.
    Falls back to disasm-based disambiguation if ctree matching fails.
    Returns None and logs failure if mapping cannot be reliably determined.
    \"\"\"
    cfunc = get_cfunc(func_ea)
    if not cfunc:
        log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=no_cfunc")
        return None

    try:
        # Get the pseudocode as lines
        sv = cfunc.get_pseudocode()
        lines = []
        for i in range(sv.size()):
            line = ida_lines.tag_remove(sv[i].line)
            lines.append(line)

        if not lines:
            log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=empty_pseudocode")
            return None

        target_line_idx = -1
        mapping_method = None

        # =======================================================================
        # STRATEGY 1: Ctree visitor with EA matching (most reliable)
        # =======================================================================
        # Use Hex-Rays ctree API to find items whose EA matches target_ea exactly
        try:
            class EAVisitor(ida_hexrays.ctree_visitor_t):
                def __init__(self, target):
                    ida_hexrays.ctree_visitor_t.__init__(self, ida_hexrays.CV_FAST)
                    self.target = target
                    self.found_items = []

                def visit_expr(self, e):
                    if e.ea == self.target:
                        self.found_items.append(('expr', e))
                    return 0

                def visit_insn(self, i):
                    if i.ea == self.target:
                        self.found_items.append(('insn', i))
                    return 0

            visitor = EAVisitor(target_ea)
            visitor.apply_to(cfunc.body, None)

            if visitor.found_items:
                log(f"[DECOMP] ctree_visitor found {{len(visitor.found_items)}} items with EA={{hex(target_ea)}}")

                # Try to map found items to pseudocode coordinates
                for item_type, item in visitor.found_items:
                    try:
                        # find_item_coords returns (line, x, y) or None
                        coords = cfunc.find_item_coords(item)
                        if coords and len(coords) >= 1:
                            line_num = coords[0]
                            if 0 < line_num < len(lines):
                                # Validate: check that the line contains expected callee
                                line_text = lines[line_num].lower()
                                disasm = idc.generate_disasm_line(target_ea, 0).lower()

                                # For call instructions, verify callee appears in line
                                if "call" in disasm:
                                    callee_raw = idc.print_operand(target_ea, 0)
                                    callee = callee_raw.strip("_").lower()
                                    if callee in line_text:
                                        target_line_idx = line_num
                                        mapping_method = f"ctree_ea_{{item_type}}"
                                        log(f"[DECOMP] ctree mapped EA={{hex(target_ea)}} to line {{line_num}} (validated callee={{callee}})")
                                        break
                                    else:
                                        log(f"[DECOMP] ctree line {{line_num}} rejected: callee '{{callee}}' not in line")
                                else:
                                    # Non-call instruction - validate it contains expected patterns
                                    mnem = idc.print_insn_mnem(target_ea)
                                    disasm_lower = idc.generate_disasm_line(target_ea, 0).lower()

                                    # For memory compare/load, line should contain dereference
                                    if mnem in ["cmp", "mov", "movzx", "movsx", "test"]:
                                        if "*" in line_text:
                                            # Check for immediate value in compare
                                            import re
                                            imm_match = re.search(r',\\s*([0-9A-Fa-f]+)h?\\b', disasm_lower)
                                            if imm_match:
                                                imm_val = int(imm_match.group(1).rstrip('h'), 16)
                                                # Check if line contains decimal or char representation
                                                if str(imm_val) in line_text or (32 <= imm_val < 127 and chr(imm_val) in line_text):
                                                    target_line_idx = line_num
                                                    mapping_method = f"ctree_ea_{{item_type}}_validated"
                                                    log(f"[DECOMP] ctree mapped EA={{hex(target_ea)}} to line {{line_num}} (validated deref+imm)")
                                                    break
                                                else:
                                                    log(f"[DECOMP] ctree line {{line_num}} rejected: deref present but imm {{imm_val}} not found")
                                            else:
                                                # No immediate, just accept deref pattern
                                                target_line_idx = line_num
                                                mapping_method = f"ctree_ea_{{item_type}}"
                                                log(f"[DECOMP] ctree mapped EA={{hex(target_ea)}} to line {{line_num}} (deref pattern)")
                                                break
                                        else:
                                            log(f"[DECOMP] ctree line {{line_num}} rejected: mem access but no deref in line")
                                    else:
                                        # Other non-call instructions - accept
                                        target_line_idx = line_num
                                        mapping_method = f"ctree_ea_{{item_type}}"
                                        log(f"[DECOMP] ctree mapped EA={{hex(target_ea)}} to line {{line_num}} (non-call)")
                                        break
                    except Exception as e:
                        log(f"[DECOMP] find_item_coords failed for {{item_type}}: {{e}}")
            else:
                log(f"[DECOMP] ctree_visitor found no items with EA={{hex(target_ea)}}")

        except Exception as e:
            log(f"[DECOMP] ctree_visitor exception: {{e}}")

        # =======================================================================
        # STRATEGY 2: Callee-based matching with disasm disambiguation (fallback)
        # =======================================================================
        if target_line_idx == -1:
            disasm = idc.generate_disasm_line(target_ea, 0)
            if "call" in disasm.lower():
                callee_raw = idc.print_operand(target_ea, 0)
                callee = callee_raw.strip("_").lower()

                candidate_lines = []
                for i, line in enumerate(lines):
                    if callee in line.lower() and i > 0:
                        candidate_lines.append(i)

                if len(candidate_lines) == 1:
                    target_line_idx = candidate_lines[0]
                    mapping_method = "callee_unique"
                    log(f"[DECOMP] Unique callee match for {{callee}} at line {{target_line_idx}}")
                elif len(candidate_lines) > 1:
                    log(f"[DECOMP] Multiple callee matches ({{len(candidate_lines)}}) for {{callee}} at {{hex(target_ea)}}")

                    # Use disassembly-based disambiguation
                    call_info = extract_call_args_from_disasm(target_ea)
                    disambiguated = disambiguate_callee_line(lines, candidate_lines, callee, call_info)

                    if disambiguated != -1:
                        target_line_idx = disambiguated
                        mapping_method = "disasm_disambiguated"
                    else:
                        # Cannot validate any candidate - reject all
                        log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=callee_{{callee}}_unvalidated_count={{len(candidate_lines)}}")
                        return None
                elif len(candidate_lines) == 0:
                    log(f"[DECOMP] No callee matches for {{callee}} at {{hex(target_ea)}}")

        # =======================================================================
        # STRATEGY 3: Memory dereference pattern matching (for UAF use sites)
        # =======================================================================
        if target_line_idx == -1:
            mnem = idc.print_insn_mnem(target_ea)
            disasm_line = idc.generate_disasm_line(target_ea, 0).lower()

            if mnem in ["mov", "movzx", "movsx", "cmp", "test"]:
                # This is a memory access - look for dereference patterns
                # For UAF, we're looking for lines like: if (*ptr == value) or *ptr = value

                # Extract the immediate value if present (e.g., 41h = 'A' = 65)
                import re
                imm_match = re.search(r',\\s*([0-9A-Fa-f]+)h?\\s*;?', disasm_line)
                imm_value = None
                if imm_match:
                    try:
                        imm_hex = imm_match.group(1).rstrip('h')
                        imm_value = int(imm_hex, 16)
                    except:
                        pass

                # Find lines with pointer dereference
                deref_candidates = []
                for i, line in enumerate(lines):
                    if i == 0:  # Skip function signature
                        continue
                    if "*" in line:
                        # Check if this line has the immediate value
                        if imm_value is not None:
                            # Look for the decimal or char representation
                            imm_str = str(imm_value)
                            char_repr = chr(imm_value) if 32 <= imm_value < 127 else None
                            if imm_str in line or (char_repr and ("'" + char_repr + "'") in line):
                                deref_candidates.append((i, "imm_match"))
                            else:
                                deref_candidates.append((i, "deref_only"))
                        else:
                            deref_candidates.append((i, "deref_only"))

                # Prioritize lines with immediate value match
                imm_matches = [c for c in deref_candidates if c[1] == "imm_match"]
                if len(imm_matches) == 1:
                    target_line_idx = imm_matches[0][0]
                    mapping_method = "deref_imm_unique"
                elif len(imm_matches) > 1:
                    # Multiple matches with imm value - pick first (usually correct for UAF)
                    target_line_idx = imm_matches[0][0]
                    mapping_method = "deref_imm_first_of_" + str(len(imm_matches))
                elif len(deref_candidates) > 0:
                    # No imm matches, but have deref candidates - be conservative
                    log("[DECOMP] Found " + str(len(deref_candidates)) + " deref candidates but no imm match for " + hex(target_ea))
                    # Don't pick blindly - could be wrong

        # =======================================================================
        # VALIDATION: Verify the selected line matches expectations
        # =======================================================================
        if target_line_idx != -1:
            selected_line = lines[target_line_idx]
            disasm = idc.generate_disasm_line(target_ea, 0).lower()

            # For malloc with +16 pattern, verify the pseudocode shows the addition
            if "malloc" in disasm:
                call_info = extract_call_args_from_disasm(target_ea)
                if call_info.get("size_add_16"):
                    if "+ 16" in selected_line or "+16" in selected_line:
                        log(f"[DECOMP] Validation PASS: malloc line contains +16 as expected")
                    else:
                        # The selected line doesn't match the disasm pattern - reject it
                        log(f"[DECOMP] Validation FAIL: expected +16 in malloc line but got: {{selected_line.strip()[:60]}}")
                        log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=validation_failed_no_add16")
                        return None

        # If all strategies fail, log and return None (NO silent fallback)
        if target_line_idx == -1:
            log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=no_mapping_found")
            return None

        log(f"[DECOMP] slice_found id={{finding_id}} sink={{hex(target_ea)}} line={{target_line_idx}} method={{mapping_method}}")

        # Extract context around target line
        start = max(0, target_line_idx - context_lines // 2)
        end = min(len(lines), target_line_idx + context_lines // 2 + 1)

        result_lines = []
        for i in range(start, end):
            prefix = ">>> " if i == target_line_idx else "    "
            result_lines.append(f"{{prefix}}{{lines[i]}}")

        return "\\n".join(result_lines)

    except Exception as e:
        log(f"[DECOMP] slice_not_found id={{finding_id}} sink={{hex(target_ea)}} reason=exception_{{str(e)}}")
        return None

def get_full_pseudocode(func_ea: int) -> str:
    \"\"\"Get full pseudocode for a function.\"\"\"
    cfunc = get_cfunc(func_ea)
    if not cfunc:
        return None

    try:
        sv = cfunc.get_pseudocode()
        lines = []
        for i in range(sv.size()):
            line = ida_lines.tag_remove(sv[i].line)
            lines.append(line)
        return "\\n".join(lines)
    except Exception as e:
        return None

def rename_variables_in_function(func_ea: int, findings_in_func: list):
    \"\"\"Attempt to rename variables in a function based on usage patterns.\"\"\"
    if not HAS_HEXRAYS:
        return

    cfunc = get_cfunc(func_ea)
    if not cfunc:
        return

    func_name = ida_name.get_name(func_ea) or f"sub_{{func_ea:x}}"
    log(f"[RENAME] Analyzing variables in {{func_name}}...")

    try:
        lvars = cfunc.lvars
        renamed_count = 0

        for i, lvar in enumerate(lvars):
            old_name = lvar.name
            new_name = None
            reason = None

            # Skip if already has a meaningful name
            if not old_name.startswith("v") and not old_name.startswith("a"):
                continue

            # Check variable type and usage
            var_type = str(lvar.type())

            # Size-related naming
            if "size_t" in var_type or "unsigned" in var_type:
                if lvar.width == 4 or lvar.width == 8:
                    new_name = f"size_{{i}}"
                    reason = "type is size_t/unsigned, likely size variable"

            # Buffer-related naming
            if "char *" in var_type or "void *" in var_type or "_BYTE *" in var_type:
                new_name = f"buf_{{i}}"
                reason = "type is pointer, likely buffer"

            # Check if used in dangerous functions
            for finding in findings_in_func:
                sink_ea = finding.get("analysis", {{}}).get("call_ea", 0)
                if sink_ea:
                    # This is a simplified check - in reality we'd trace data flow
                    callee = finding.get("analysis", {{}}).get("callee", "")
                    if "strcpy" in callee.lower() or "strcat" in callee.lower():
                        if "char *" in var_type:
                            new_name = f"dest_buf"
                            reason = f"used as destination in {{callee}}"
                    elif "malloc" in callee.lower():
                        if "size" in var_type.lower() or lvar.width in [4, 8]:
                            new_name = f"alloc_size"
                            reason = "used as malloc size argument"

            if new_name and new_name != old_name:
                try:
                    # Note: Actually renaming requires modify_user_lvars
                    # For now, we just log the suggestion
                    log(f"[RENAME] func@{{hex(func_ea)}} lvar {{old_name}} -> {{new_name}} (reason: {{reason}})")
                    type_changes.append({{
                        "type": "rename",
                        "function": hex(func_ea),
                        "old_name": old_name,
                        "new_name": new_name,
                        "reason": reason
                    }})
                    renamed_count += 1
                except:
                    pass

        if renamed_count > 0:
            log(f"[RENAME] Suggested {{renamed_count}} variable renames in {{func_name}}")

    except Exception as e:
        log(f"[RENAME] Error analyzing variables: {{str(e)}}")

def get_disasm_context(ea: int, before: int = 8, after: int = 4) -> list:
    \"\"\"Get disassembly context around an address.\"\"\"
    func = ida_funcs.get_func(ea)
    if not func:
        return []

    lines = []

    # Get lines before
    prev_eas = []
    cur = ea
    for _ in range(before):
        cur = idc.prev_head(cur)
        if cur == idc.BADADDR or cur < func.start_ea:
            break
        prev_eas.insert(0, cur)

    for addr in prev_eas:
        lines.append({{
            "ea": hex(addr),
            "disasm": idc.generate_disasm_line(addr, 0),
            "is_target": False
        }})

    # Target line
    lines.append({{
        "ea": hex(ea),
        "disasm": idc.generate_disasm_line(ea, 0),
        "is_target": True
    }})

    # Get lines after
    cur = ea
    for _ in range(after):
        cur = idc.next_head(cur)
        if cur == idc.BADADDR or cur >= func.end_ea:
            break
        lines.append({{
            "ea": hex(cur),
            "disasm": idc.generate_disasm_line(cur, 0),
            "is_target": False
        }})

    return lines

def identify_input_source(func_ea: int, call_ea: int) -> dict:
    \"\"\"Try to identify the source of input data (argv, stdin, file).\"\"\"
    func = ida_funcs.get_func(func_ea)
    if not func:
        return {{"source": "unknown", "evidence": None}}

    sources = []

    # Check function arguments - if main, first args are argc/argv
    func_name = ida_name.get_name(func_ea) or ""
    if func_name == "main":
        sources.append({{"source": "argv", "evidence": "function is main(), has argv parameter"}})

    # Scan the function for input-related calls before our target
    ea = func.start_ea
    while ea < call_ea:
        mnem = idc.print_insn_mnem(ea)
        if mnem == "call":
            target = idc.print_operand(ea, 0).lower()

            if any(x in target for x in ["read", "fread", "recv", "recvfrom"]):
                disasm = idc.generate_disasm_line(ea, 0)
                sources.append({{"source": "file/network", "evidence": f"{{disasm}} at {{hex(ea)}}"}})

            if any(x in target for x in ["fgets", "gets", "scanf", "getline"]):
                disasm = idc.generate_disasm_line(ea, 0)
                sources.append({{"source": "stdin", "evidence": f"{{disasm}} at {{hex(ea)}}"}})

            if any(x in target for x in ["fopen", "open"]):
                disasm = idc.generate_disasm_line(ea, 0)
                sources.append({{"source": "file", "evidence": f"{{disasm}} at {{hex(ea)}}"}})

            if "argv" in target or "getenv" in target:
                disasm = idc.generate_disasm_line(ea, 0)
                sources.append({{"source": "argv/env", "evidence": f"{{disasm}} at {{hex(ea)}}"}})

        ea = idc.next_head(ea)

    # Check for array indexing with argv pattern
    if func_name == "main":
        # Look for [r12+...] or similar argv access patterns
        ea = func.start_ea
        while ea < call_ea:
            disasm = idc.generate_disasm_line(ea, 0).lower()
            if "r12" in disasm or "rsi" in disasm:  # Common argv registers
                if "[" in disasm and ("+8" in disasm or "+10h" in disasm or "+16" in disasm):
                    sources.append({{"source": "argv", "evidence": f"array access pattern at {{hex(ea)}}"}})
                    break
            ea = idc.next_head(ea)

    if sources:
        return sources[0]  # Return most relevant
    return {{"source": "unknown", "evidence": "could not determine input source"}}

def get_callee_name(call_ea: int) -> str:
    \"\"\"Get the callee name for a call instruction, always returning a value.\"\"\"
    target = idc.print_operand(call_ea, 0)
    if not target:
        return "unknown"

    # Clean up the name
    target = target.strip()

    # If it's a register-based indirect call
    if target.startswith("r") or target.startswith("e"):
        return f"indirect_{{target}}"

    # If it's a memory reference
    if target.startswith("["):
        return "indirect_mem"

    return target

def analyze_call_for_overflow(call_ea: int, callee_name: str) -> dict:
    \"\"\"Analyze a call site for potential buffer overflow.\"\"\"
    func = ida_funcs.get_func(call_ea)
    if not func:
        return None

    func_name = ida_name.get_name(func.start_ea) or f"sub_{{func.start_ea:x}}"

    # Get context
    context = get_disasm_context(call_ea)

    # Try to identify destination buffer type
    dst_info = "unknown"
    for ctx in context:
        disasm = ctx.get("disasm", "").lower()
        if "lea" in disasm and ("rdi" in disasm or "edi" in disasm):
            if "rbp" in disasm or "rsp" in disasm:
                dst_info = "stack_buffer"
            elif "[r" in disasm:
                dst_info = "heap_buffer"

    # Get pseudocode context (pass identifying info for logging)
    pseudo_context = get_pseudocode_at_address(func.start_ea, call_ea, 12, f"BOF@{{hex(call_ea)}}")

    # Identify input source
    input_source = identify_input_source(func.start_ea, call_ea)

    return {{
        "call_ea": call_ea,
        "callee": callee_name,
        "function_ea": func.start_ea,
        "function_name": func_name,
        "dst_type": dst_info,
        "context": context,
        "pseudocode_context": pseudo_context,
        "input_source": input_source,
    }}

def analyze_call_for_format_string(call_ea: int, callee_name: str) -> dict:
    \"\"\"Analyze a call site for potential format string vulnerability.\"\"\"
    func = ida_funcs.get_func(call_ea)
    if not func:
        return None

    func_name = ida_name.get_name(func.start_ea) or f"sub_{{func.start_ea:x}}"

    # Check if format argument appears to be non-constant
    is_likely_vuln = False
    confidence = "possible"

    context = get_disasm_context(call_ea)
    for ctx in context:
        disasm = ctx.get("disasm", "").lower()
        # If format arg comes from stack/reg, likely user controlled
        if "rsi" in disasm or "rdi" in disasm:
            if "lea" in disasm and ("rbp" in disasm or "rsp" in disasm):
                is_likely_vuln = True
                confidence = "likely"
            elif "mov" in disasm and ("[rbp" in disasm or "[rsp" in disasm):
                is_likely_vuln = True
                confidence = "likely"

    # For __printf_chk, format is second arg (rsi)
    if "printf_chk" in callee_name.lower():
        is_likely_vuln = True

    # Get pseudocode context (pass identifying info for logging)
    pseudo_context = get_pseudocode_at_address(func.start_ea, call_ea, 12, f"FMT@{{hex(call_ea)}}")

    # Identify input source
    input_source = identify_input_source(func.start_ea, call_ea)

    return {{
        "call_ea": call_ea,
        "callee": callee_name,
        "function_ea": func.start_ea,
        "function_name": func_name,
        "is_likely_vuln": is_likely_vuln,
        "confidence": confidence,
        "context": context,
        "pseudocode_context": pseudo_context,
        "input_source": input_source,
    }}

def analyze_malloc_for_integer_overflow(call_ea: int, callee_name: str) -> dict:
    \"\"\"Analyze malloc call for potential integer overflow in size calculation.\"\"\"
    func = ida_funcs.get_func(call_ea)
    if not func:
        return None

    func_name = ida_name.get_name(func.start_ea) or f"sub_{{func.start_ea:x}}"
    context = get_disasm_context(call_ea, before=12, after=6)

    # Look for arithmetic operations before malloc
    arith_ops = []
    has_input_derived_size = False
    has_subsequent_copy = False
    copy_ea = None

    for ctx in context:
        if ctx.get("is_target"):
            continue
        disasm = ctx.get("disasm", "").lower()
        ea = int(ctx.get("ea", "0"), 16)
        if ea >= call_ea:
            # Check for subsequent memcpy/copy operations
            if any(x in disasm for x in ["memcpy", "strcpy", "memmove", "rep movs"]):
                has_subsequent_copy = True
                copy_ea = ea
            continue

        # Check for arithmetic that affects size
        if any(op in disasm for op in ["add ", "shl ", "imul ", "mul ", "lea "]):
            if "rdi" in disasm or "edi" in disasm:
                arith_ops.append({{
                    "ea": ctx["ea"],
                    "disasm": ctx["disasm"],
                    "type": "size_computation"
                }})
            elif any(reg in disasm for reg in ["rax", "eax", "rcx", "ecx", "rdx", "edx"]):
                arith_ops.append({{
                    "ea": ctx["ea"],
                    "disasm": ctx["disasm"],
                    "type": "arithmetic"
                }})

        # Check for input-derived patterns
        if "[" in disasm and any(x in disasm for x in ["rax", "rbx", "rcx", "rdx", "r8", "r9"]):
            has_input_derived_size = True

    # Scan forward for subsequent copy operations
    ea = call_ea
    for _ in range(20):
        ea = idc.next_head(ea)
        if ea == idc.BADADDR or ea >= func.end_ea:
            break
        disasm = idc.generate_disasm_line(ea, 0).lower()
        if any(x in disasm for x in ["memcpy", "rep movs", "strcpy"]):
            has_subsequent_copy = True
            copy_ea = ea
            break

    # Determine confidence
    if arith_ops and has_input_derived_size and has_subsequent_copy:
        confidence = "likely"
    elif arith_ops and (has_input_derived_size or has_subsequent_copy):
        confidence = "likely"
    elif arith_ops:
        confidence = "possible"
    else:
        confidence = "pattern-only"

    # Get pseudocode context (pass identifying info for logging)
    pseudo_context = get_pseudocode_at_address(func.start_ea, call_ea, 12, f"INT@{{hex(call_ea)}}")

    # Identify input source
    input_source = identify_input_source(func.start_ea, call_ea)

    return {{
        "call_ea": call_ea,
        "callee": callee_name,
        "function_ea": func.start_ea,
        "function_name": func_name,
        "arithmetic_ops": arith_ops,
        "has_input_derived_size": has_input_derived_size,
        "has_subsequent_copy": has_subsequent_copy,
        "copy_ea": hex(copy_ea) if copy_ea else None,
        "context": context,
        "pseudocode_context": pseudo_context,
        "input_source": input_source,
        "confidence": confidence,
    }}

def track_free_sites():
    \"\"\"Find all free() calls and track the freed pointers.\"\"\"
    global free_sites

    for func_ea in idautils.Functions():
        func = ida_funcs.get_func(func_ea)
        if not func:
            continue

        func_frees = []
        ea = func.start_ea
        while ea < func.end_ea:
            mnem = idc.print_insn_mnem(ea)
            if mnem == "call":
                target_name = idc.print_operand(ea, 0).lower()
                if "free" in target_name and "freeifaddrs" not in target_name:
                    # Track what register holds the pointer
                    prev_ea = idc.prev_head(ea)
                    ptr_source = "unknown"
                    if prev_ea != idc.BADADDR:
                        prev_disasm = idc.generate_disasm_line(prev_ea, 0)
                        if "rdi" in prev_disasm.lower():
                            if "[rbp" in prev_disasm or "[rsp" in prev_disasm:
                                ptr_source = "stack_var"
                            elif "rbx" in prev_disasm or "r12" in prev_disasm or "r13" in prev_disasm:
                                ptr_source = prev_disasm.split(",")[-1].strip() if "," in prev_disasm else "reg"

                    func_frees.append({{
                        "free_ea": ea,
                        "ptr_source": ptr_source,
                        "callee": get_callee_name(ea),
                        "disasm": idc.generate_disasm_line(ea, 0)
                    }})
            ea = idc.next_head(ea)

        if func_frees:
            free_sites[func_ea] = func_frees

def find_closest_preceding_free(use_ea: int, all_frees: list) -> dict:
    \"\"\"Find the free() call that most closely precedes use_ea.\"\"\"
    closest = None
    closest_dist = float('inf')

    for free_info in all_frees:
        free_ea = free_info["free_ea"]
        if free_ea < use_ea:
            dist = use_ea - free_ea
            if dist < closest_dist:
                closest_dist = dist
                closest = free_info

    return closest

def find_uaf_patterns() -> list:
    \"\"\"Find use-after-free patterns by looking for memory access after free.\"\"\"
    uaf_findings = []
    seen_uses = set()  # Track use_ea to avoid duplicates

    for func_ea, frees in free_sites.items():
        func = ida_funcs.get_func(func_ea)
        if not func:
            continue

        func_name = ida_name.get_name(func_ea) or f"sub_{{func_ea:x}}"

        for free_info in frees:
            free_ea = free_info["free_ea"]
            ptr_source = free_info["ptr_source"]

            # Scan instructions after free for use of same pointer
            ea = free_ea
            instructions_scanned = 0
            max_scan_distance = 50  # Limit scan to avoid cross-branch false positives

            while ea < func.end_ea and instructions_scanned < max_scan_distance:
                ea = idc.next_head(ea)
                if ea == idc.BADADDR:
                    break

                instructions_scanned += 1
                mnem = idc.print_insn_mnem(ea)
                disasm = idc.generate_disasm_line(ea, 0)

                # Stop scanning if we hit another free() - that starts a new region
                if mnem == "call":
                    target = idc.print_operand(ea, 0).lower()
                    if "free" in target and "freeifaddrs" not in target:
                        break
                    continue

                # Check for memory dereference patterns
                is_use = False
                use_type = None

                if mnem in ["mov", "movzx", "movsx"]:
                    if ptr_source != "unknown":
                        src = ptr_source.lower().replace(" ", "")
                        if f"[{{src}}" in disasm.lower().replace(" ", "") or f"byte ptr [{{src}}" in disasm.lower().replace(" ", ""):
                            is_use = True
                            use_type = "load"

                if mnem == "cmp" or mnem == "test":
                    if ptr_source != "unknown":
                        src = ptr_source.lower()
                        if f"[{{src}}" in disasm.lower() or f"ptr [{{src}}" in disasm.lower():
                            is_use = True
                            use_type = "compare"

                # Generic dereference detection
                if not is_use and "[" in disasm:
                    for reg in ["rbx", "r12", "r13", "r14", "r15"]:
                        if f"[{{reg}}]" in disasm.lower() or f"byte ptr [{{reg}}]" in disasm.lower():
                            is_use = True
                            use_type = "possible_deref"
                            ptr_source = reg
                            break

                if is_use:
                    # Skip if we've already recorded this use site
                    if ea in seen_uses:
                        continue
                    seen_uses.add(ea)

                    # Find the closest preceding free to this use site
                    # This handles cases where multiple frees exist and we need the right one
                    closest_free = find_closest_preceding_free(ea, frees)
                    if closest_free:
                        actual_free_ea = closest_free["free_ea"]
                        actual_free_callee = closest_free.get("callee", "_free")
                    else:
                        actual_free_ea = free_ea
                        actual_free_callee = free_info.get("callee", "_free")

                    context = get_disasm_context(ea)
                    # Get pseudocode context centered on the USE site (not free site)
                    pseudo_context = get_pseudocode_at_address(func_ea, ea, 12, f"UAF_USE@{{hex(ea)}}")
                    input_source = identify_input_source(func_ea, actual_free_ea)

                    uaf_findings.append({{
                        "type": "UseAfterFree",
                        "cwe": ["CWE-416"],
                        "function_ea": func_ea,
                        "function_name": func_name,
                        "free_ea": actual_free_ea,
                        "free_callee": actual_free_callee,
                        "use_ea": ea,
                        "ptr_source": ptr_source,
                        "use_type": use_type,
                        "use_disasm": disasm,
                        "context": context,
                        "pseudocode_context": pseudo_context,
                        "input_source": input_source,
                        "confidence": "confirmed" if use_type in ["load", "compare"] else "likely",
                    }})
                    log(f"[UAF] Found use-after-free: free@{{hex(actual_free_ea)}} -> use@{{hex(ea)}} ({{use_type}})")
                    break

    return uaf_findings

def scan_all_functions() -> list:
    \"\"\"Scan all functions for dangerous patterns.\"\"\"
    candidates = []
    functions_scanned = 0

    log("[STAGE] Scanning all functions for dangerous patterns...")

    for func_ea in idautils.Functions():
        func = ida_funcs.get_func(func_ea)
        if not func:
            continue

        functions_scanned += 1
        func_name = ida_name.get_name(func_ea) or f"sub_{{func_ea:x}}"

        ea = func.start_ea
        while ea < func.end_ea:
            mnem = idc.print_insn_mnem(ea)
            if mnem == "call":
                target_name = idc.print_operand(ea, 0)
                callee = get_callee_name(ea)
                target_lower = target_name.lower()

                for sink_name, sink_info in DANGEROUS_SINKS.items():
                    if sink_name in target_lower:
                        category = sink_info["category"]

                        if category == "copy":
                            analysis = analyze_call_for_overflow(ea, callee)
                            if analysis:
                                candidates.append({{
                                    "type": sink_info["type"],
                                    "cwe": sink_info["cwe"],
                                    "category": category,
                                    "sink_name": sink_name,
                                    "confidence": sink_info["confidence"],
                                    "analysis": analysis,
                                }})
                                log(f"[CANDIDATE] {{sink_info['type']}} at {{hex(ea)}} ({{callee}})")

                        elif category == "format":
                            analysis = analyze_call_for_format_string(ea, callee)
                            if analysis and analysis.get("is_likely_vuln"):
                                candidates.append({{
                                    "type": sink_info["type"],
                                    "cwe": sink_info["cwe"],
                                    "category": category,
                                    "sink_name": sink_name,
                                    "confidence": analysis.get("confidence", sink_info["confidence"]),
                                    "analysis": analysis,
                                }})
                                log(f"[CANDIDATE] {{sink_info['type']}} at {{hex(ea)}} ({{callee}})")

                        elif category == "alloc":
                            analysis = analyze_malloc_for_integer_overflow(ea, callee)
                            if analysis and analysis.get("arithmetic_ops"):
                                # Only emit if confidence is at least likely
                                conf = analysis.get("confidence", "possible")
                                if conf in ["likely", "confirmed"]:
                                    candidates.append({{
                                        "type": "IntegerOverflow",
                                        "cwe": ["CWE-190", "CWE-122"],
                                        "category": category,
                                        "sink_name": sink_name,
                                        "confidence": conf,
                                        "analysis": analysis,
                                    }})
                                    log(f"[CANDIDATE] IntegerOverflow at {{hex(ea)}} (confidence={{conf}})")
                                else:
                                    log(f"[SKIP] IntegerOverflow at {{hex(ea)}} (confidence={{conf}}, pattern-only)")
                        break

            ea = idc.next_head(ea)

    log(f"[STAGE] Scanned {{functions_scanned}} functions, found {{len(candidates)}} raw candidates")
    return candidates, functions_scanned

def deduplicate_findings(candidates: list, uaf_findings: list) -> tuple:
    \"\"\"Deduplicate findings using composite keys.\"\"\"
    deduped = []
    seen_keys = set()
    duplicates = 0

    log("[STAGE] Deduplicating findings...")

    for c in candidates:
        if c["type"] == "BufferOverflow":
            analysis = c["analysis"]
            key = ("BufferOverflow", analysis["call_ea"], analysis["callee"], analysis.get("dst_type", "unknown"))
            if key not in seen_keys:
                seen_keys.add(key)
                deduped.append(c)
            else:
                duplicates += 1

        elif c["type"] == "FormatString":
            analysis = c["analysis"]
            key = ("FormatString", analysis["call_ea"], analysis["callee"])
            if key not in seen_keys:
                seen_keys.add(key)
                deduped.append(c)
            else:
                duplicates += 1

        elif c["type"] == "IntegerOverflow":
            analysis = c["analysis"]
            arith_key = analysis["arithmetic_ops"][0]["ea"] if analysis["arithmetic_ops"] else "none"
            key = ("IntegerOverflow", analysis["call_ea"], arith_key)
            if key not in seen_keys:
                seen_keys.add(key)
                deduped.append(c)
            else:
                duplicates += 1

    # Process UAF findings - key by use_ea to avoid duplicates
    for uaf in uaf_findings:
        key = ("UseAfterFree", uaf["use_ea"], uaf.get("ptr_source", "unknown"))
        if key not in seen_keys:
            seen_keys.add(key)
            deduped.append({{
                "type": "UseAfterFree",
                "cwe": uaf["cwe"],
                "category": "uaf",
                "sink_name": "free+use",
                "confidence": uaf["confidence"],
                "analysis": uaf,
            }})
        else:
            duplicates += 1

    log(f"[STAGE] Deduplication complete: {{len(deduped)}} unique findings, {{duplicates}} duplicates suppressed")
    return deduped, duplicates

def assign_finding_ids(findings: list) -> list:
    \"\"\"Assign unique IDs to findings.\"\"\"
    type_counters = {{}}

    for f in findings:
        ftype = f["type"]
        if ftype not in type_counters:
            type_counters[ftype] = 0
        type_counters[ftype] += 1

        prefix = {{
            "FormatString": "FMT",
            "BufferOverflow": "BOF",
            "UseAfterFree": "UAF",
            "IntegerOverflow": "INT",
        }}.get(ftype, "VLN")

        f["id"] = f"{{prefix}}-{{type_counters[ftype]:04d}}"

    return findings

def annotate_database(findings: list):
    \"\"\"Add comments to IDA database at finding locations.\"\"\"
    log("[STAGE] Annotating IDA database with findings...")

    for f in findings:
        analysis = f.get("analysis", {{}})
        fid = f.get("id", "???")
        ftype = f.get("type", "Unknown")
        cwes = ", ".join(f.get("cwe", []))

        if f["type"] == "UseAfterFree":
            free_ea = analysis.get("free_ea", 0)
            use_ea = analysis.get("use_ea", 0)

            if free_ea:
                comment = f"[{{fid}}] {{ftype}} - FREE site ({{cwes}})"
                idc.set_cmt(free_ea, comment, 0)
                comment_sites.append({{"ea": hex(free_ea), "comment": comment, "type": "free_site"}})
                log(f"[COMMENT] set_cmt @{{hex(free_ea)}}: {{comment}}")

            if use_ea:
                comment = f"[{{fid}}] {{ftype}} - USE after free ({{cwes}})"
                idc.set_cmt(use_ea, comment, 0)
                comment_sites.append({{"ea": hex(use_ea), "comment": comment, "type": "use_site"}})
                log(f"[COMMENT] set_cmt @{{hex(use_ea)}}: {{comment}}")
        else:
            call_ea = analysis.get("call_ea", 0)
            if call_ea:
                callee = analysis.get("callee", "unknown")
                comment = f"[{{fid}}] {{ftype}} sink: {{callee}} ({{cwes}})"
                idc.set_cmt(call_ea, comment, 0)
                comment_sites.append({{"ea": hex(call_ea), "comment": comment, "type": "sink"}})
                log(f"[COMMENT] set_cmt @{{hex(call_ea)}}: {{comment}}")

        # Add function comment
        func_ea = analysis.get("function_ea", 0)
        if func_ea:
            existing = idc.get_func_cmt(func_ea, 0) or ""
            new_line = f"[{{fid}}] {{ftype}} ({{cwes}})"
            if new_line not in existing:
                new_comment = existing + "\\n" + new_line if existing else new_line
                idc.set_func_cmt(func_ea, new_comment.strip(), 0)
                log(f"[COMMENT] set_func_cmt @{{hex(func_ea)}}")

    # Write comment summary
    log(f"[COMMENT] === Comment Write Summary ===")
    log(f"[COMMENT] Total comments written: {{len(comment_sites)}}")
    for cs in comment_sites:
        log(f"[COMMENT]   {{cs['ea']}}: {{cs['type']}} - {{cs['comment'][:50]}}...")

def generate_why_explanation(finding: dict) -> list:
    \"\"\"Generate concise bullet-point explanation of why this is a vulnerability.\"\"\"
    ftype = finding.get("type")
    analysis = finding.get("analysis", {{}})
    bullets = []

    if ftype == "BufferOverflow":
        callee = analysis.get("callee", "unknown")
        dst = analysis.get("dst_type", "unknown")
        bullets.append(f"Dangerous function `{{callee}}` copies data without bounds checking")
        bullets.append(f"Destination is {{dst}}, which has fixed size")
        src = analysis.get("input_source", {{}})
        if src.get("source") != "unknown":
            bullets.append(f"Source appears to be {{src.get('source')}}: {{src.get('evidence', 'N/A')}}")

    elif ftype == "FormatString":
        callee = analysis.get("callee", "unknown")
        bullets.append(f"Format function `{{callee}}` uses potentially user-controlled format string")
        bullets.append("Format specifiers like %n, %x, %s can read/write arbitrary memory")
        src = analysis.get("input_source", {{}})
        if src.get("source") != "unknown":
            bullets.append(f"Format string may come from {{src.get('source')}}")

    elif ftype == "IntegerOverflow":
        ops = analysis.get("arithmetic_ops", [])
        if ops:
            bullets.append(f"Size computation involves arithmetic: `{{ops[0]['disasm']}}`")
        if analysis.get("has_input_derived_size"):
            bullets.append("Computed size appears to be derived from input data")
        if analysis.get("has_subsequent_copy"):
            bullets.append(f"Subsequent copy operation at {{analysis.get('copy_ea', 'N/A')}} may overflow")
        bullets.append("Integer wrap can cause small allocation followed by large copy")

    elif ftype == "UseAfterFree":
        use_type = analysis.get("use_type", "access")
        bullets.append(f"Memory is {{use_type}}ed after being freed")
        bullets.append(f"Free at {{hex(analysis.get('free_ea', 0))}}, use at {{hex(analysis.get('use_ea', 0))}}")
        bullets.append("Freed chunk may be reallocated and corrupted")

    return bullets

def generate_findings_json(binary_info: dict, findings: list, functions_scanned: int,
                           raw_count: int, dup_count: int, ida_info: dict) -> dict:
    \"\"\"Generate the findings JSON structure.\"\"\"

    json_findings = []
    for f in findings:
        analysis = f.get("analysis", {{}})

        # Build context disassembly strings
        context_lines = []
        for ctx in analysis.get("context", []):
            prefix = ">>> " if ctx.get("is_target") else "    "
            context_lines.append(f"{{prefix}}{{ctx['ea']}}: {{ctx['disasm']}}")

        # Get sink-centered pseudocode context
        pseudo_context = analysis.get("pseudocode_context")

        # Get callee - ensure it's always populated
        call_ea = analysis.get("call_ea", 0) or analysis.get("use_ea", 0)
        callee = analysis.get("callee")

        # For UAF, the sink is the USE site (dereference), not the free() call
        # So callee should describe the use operation, not "_free"
        if not callee and f["type"] == "UseAfterFree":
            use_type = analysis.get("use_type", "deref")
            # Map use_type to descriptive sink callee
            use_type_map = {{
                "load": "mem_load",
                "compare": "mem_compare",
                "possible_deref": "mem_deref",
            }}
            callee = use_type_map.get(use_type, "mem_deref")

        # Build why explanation
        why_bullets = generate_why_explanation(f)

        entry = {{
            "id": f.get("id"),
            "type": f.get("type"),
            "cwe": f.get("cwe", []),
            "confidence": f.get("confidence", "unknown"),
            "function": {{
                "ea": hex(analysis.get("function_ea", 0)) if analysis.get("function_ea") else None,
                "name": analysis.get("function_name"),
            }},
            "sink": {{
                "ea": hex(call_ea) if call_ea else None,
                "callee": callee or "unknown",
            }},
            "input_source": analysis.get("input_source", {{"source": "unknown"}}),
            "evidence": {{
                "disasm_context": context_lines,
                "pseudocode_context": pseudo_context,
            }},
            "why": why_bullets,
        }}

        # Add type-specific fields
        if f["type"] == "UseAfterFree":
            entry["uaf_details"] = {{
                "free_ea": hex(analysis.get("free_ea", 0)),
                "use_ea": hex(analysis.get("use_ea", 0)),
                "ptr_source": analysis.get("ptr_source"),
                "use_type": analysis.get("use_type"),
            }}
        elif f["type"] == "IntegerOverflow":
            entry["int_overflow_details"] = {{
                "arithmetic_ops": analysis.get("arithmetic_ops", []),
                "has_input_derived": analysis.get("has_input_derived_size", False),
                "has_subsequent_copy": analysis.get("has_subsequent_copy", False),
                "copy_ea": analysis.get("copy_ea"),
            }}

        json_findings.append(entry)

    return {{
        "binary": binary_info.get("input_file"),
        "sha256": None,
        "ida": ida_info,
        "analysis": {{
            "functions_scanned": functions_scanned,
            "raw_candidates": raw_count,
            "deduped_findings": len(findings),
            "duplicates_suppressed": dup_count,
            "hexrays_available": HAS_HEXRAYS,
            "type_changes": len(type_changes),
        }},
        "findings": json_findings,
    }}

def generate_evidence_md(findings: list, binary_info: dict) -> str:
    \"\"\"Generate evidence markdown report with pseudocode context.\"\"\"
    md = []
    md.append("# Static Analysis Evidence Report")
    md.append("")
    md.append(f"**Binary:** {{binary_info.get('input_file')}}")
    md.append(f"**Type:** {{binary_info.get('file_type')}}")
    md.append(f"**Architecture:** {{binary_info.get('bits')}}-bit")
    md.append(f"**Generated:** {{datetime.now().isoformat()}}")
    md.append(f"**Hex-Rays Available:** {{HAS_HEXRAYS}}")
    md.append("")
    md.append("---")
    md.append("")
    md.append("## Findings Summary")
    md.append("")
    md.append(f"Total findings: **{{len(findings)}}**")
    md.append("")

    type_counts = {{}}
    for f in findings:
        t = f.get("type", "Unknown")
        type_counts[t] = type_counts.get(t, 0) + 1

    md.append("| Type | Count |")
    md.append("|------|-------|")
    for t, c in sorted(type_counts.items()):
        md.append(f"| {{t}} | {{c}} |")
    md.append("")
    md.append("---")
    md.append("")
    md.append("## Detailed Findings")
    md.append("")

    for f in findings:
        fid = f.get("id", "???")
        ftype = f.get("type", "Unknown")
        cwes = ", ".join(f.get("cwe", []))
        analysis = f.get("analysis", {{}})

        call_ea = analysis.get("call_ea", 0) or analysis.get("use_ea", 0)
        func_name = analysis.get("function_name", "unknown")

        # For UAF, the sink is the USE site, not the free() call
        if ftype == "UseAfterFree":
            use_type = analysis.get("use_type", "deref")
            use_type_map = {{
                "load": "mem_load",
                "compare": "mem_compare",
                "possible_deref": "mem_deref",
            }}
            callee = use_type_map.get(use_type, "mem_deref")
        else:
            callee = analysis.get("callee") or "unknown"

        md.append(f"### [{{fid}}] {{ftype}} ({{cwes}}) @ {{hex(call_ea) if call_ea else 'N/A'}}")
        md.append("")
        md.append(f"**Function:** `{{func_name}}`")
        md.append(f"**Sink:** `{{callee}}`")
        md.append(f"**Confidence:** {{f.get('confidence', 'unknown')}}")
        md.append("")

        # Input source
        src = analysis.get("input_source", {{}})
        md.append(f"**Input Source:** {{src.get('source', 'unknown')}}")
        if src.get("evidence"):
            md.append(f"  - Evidence: {{src.get('evidence')}}")
        md.append("")

        # Why explanation
        why_bullets = generate_why_explanation(f)
        md.append("**Why this is a vulnerability:**")
        md.append("")
        for bullet in why_bullets:
            md.append(f"- {{bullet}}")
        md.append("")

        # Disassembly context
        md.append("**Disassembly Context:**")
        md.append("")
        md.append("```asm")
        for ctx in analysis.get("context", []):
            prefix = ">>> " if ctx.get("is_target") else "    "
            md.append(f"{{prefix}}{{ctx['ea']}}: {{ctx['disasm']}}")
        md.append("```")
        md.append("")

        # Pseudocode context (REQUIRED - sink-centered)
        pseudo = analysis.get("pseudocode_context")
        md.append("**Pseudocode Context (sink-centered):**")
        md.append("")
        if pseudo:
            md.append("```c")
            md.append(pseudo)
            md.append("```")
        else:
            md.append("*Hex-Rays decompilation not available or failed*")
        md.append("")

        # Additional details for specific types
        if ftype == "UseAfterFree":
            md.append("**UAF Details:**")
            md.append("")
            md.append(f"- Free site: `{{hex(analysis.get('free_ea', 0))}}`")
            md.append(f"- Use site: `{{hex(analysis.get('use_ea', 0))}}`")
            md.append(f"- Pointer: `{{analysis.get('ptr_source', 'unknown')}}`")
            md.append(f"- Use type: `{{analysis.get('use_type', 'unknown')}}`")
            md.append("")
        elif ftype == "IntegerOverflow":
            md.append("**Integer Overflow Details:**")
            md.append("")
            for op in analysis.get("arithmetic_ops", []):
                md.append(f"- Arithmetic: `{{op['disasm']}}` at {{op['ea']}}")
            if analysis.get("copy_ea"):
                md.append(f"- Subsequent copy at: `{{analysis.get('copy_ea')}}`")
            md.append("")

        md.append("---")
        md.append("")

    return "\\n".join(md)

def generate_pseudocode_export(findings: list) -> str:
    \"\"\"Generate pseudocode export with annotations.\"\"\"
    log("[STAGE] Generating pseudocode export...")

    if not HAS_HEXRAYS:
        return "// Hex-Rays decompiler not available\\n// Pseudocode export requires Hex-Rays license\\n"

    output = []
    output.append("/*")
    output.append(" * Annotated Pseudocode Export")
    output.append(f" * Generated: {{datetime.now().isoformat()}}")
    output.append(" * Contains decompiled functions with vulnerability findings")
    output.append(" */")
    output.append("")

    func_findings = {{}}
    for f in findings:
        analysis = f.get("analysis", {{}})
        func_ea = analysis.get("function_ea", 0)
        if func_ea:
            if func_ea not in func_findings:
                func_findings[func_ea] = []
            func_findings[func_ea].append(f)

    for func_ea, flist in func_findings.items():
        func_name = ida_name.get_name(func_ea) or f"sub_{{func_ea:x}}"

        output.append("")
        output.append("/" + "*" * 70)
        output.append(f" * Function: {{func_name}} @ {{hex(func_ea)}}")
        output.append(" * Findings:")
        for f in flist:
            cwes = ", ".join(f.get("cwe", []))
            output.append(f" *   - [{{f['id']}}] {{f['type']}} ({{cwes}})")
        output.append(" " + "*" * 70 + "/")
        output.append("")

        pseudocode = get_full_pseudocode(func_ea)
        if pseudocode:
            output.append(pseudocode)
        else:
            output.append(f"// Failed to decompile function {{func_name}}")

        output.append("")

    return "\\n".join(output)

def save_database():
    \"\"\"Save the IDA database (IDA 9.x compatible).\"\"\"
    db_path = os.path.join(OUTPUT_DIR, "database.i64")
    log(f"[STAGE] Saving database to {{db_path}}")

    try:
        # Flush all pending changes first
        idc.auto_wait()

        # Get current IDB path
        current_idb = ida_nalt.get_input_file_path() + ".i64"
        log(f"[STAGE] Current IDB: {{current_idb}}")

        # IDA 9.x: Use ida_loader.save_database
        # First save in place, then copy to output dir
        saved = False

        # Try ida_loader.save_database (IDA 9.x preferred)
        if hasattr(ida_loader, 'save_database'):
            try:
                # save_database(packbase, flags) - 0 = no flags
                ida_loader.save_database(db_path, 0)
                saved = True
                log(f"[STAGE] Used ida_loader.save_database")
            except Exception as e1:
                log(f"[STAGE] ida_loader.save_database failed: {{e1}}")

        # Fallback: Try idc.save_database
        if not saved and hasattr(idc, 'save_database'):
            try:
                idc.save_database(db_path, 0)
                saved = True
                log(f"[STAGE] Used idc.save_database")
            except Exception as e2:
                log(f"[STAGE] idc.save_database failed: {{e2}}")

        # Fallback: Just let qexit save it
        if not saved:
            log(f"[STAGE] Will rely on qexit to save database")
            # The .i64 file will be created next to the input file
            return True

        log(f"[STAGE] Database saved successfully to {{db_path}}")
        return True
    except Exception as e:
        log(f"[ERROR] Failed to save database: {{e}}")
        return False

def main():
    \"\"\"Main analysis entry point.\"\"\"
    log("=" * 70)
    log("IDA STATIC ANALYSIS - STARTING (v2 Audit Grade)")
    log("=" * 70)

    # Get binary info
    binary_info = get_basic_info()
    log(f"Binary: {{binary_info['input_file']}}")
    log(f"Type: {{binary_info['file_type']}}")
    log(f"Bits: {{binary_info['bits']}}")

    # Phase 1: Apply libc prototypes
    apply_libc_prototypes()

    # Phase 2: Track free sites
    log("[STAGE] Tracking free() call sites...")
    track_free_sites()
    log(f"[STAGE] Found {{len(free_sites)}} functions with free() calls")

    # Phase 3: Scan for dangerous patterns
    candidates, functions_scanned = scan_all_functions()
    raw_count = len(candidates)

    # Phase 4: Find UAF patterns
    uaf_findings = find_uaf_patterns()
    log(f"[STAGE] Found {{len(uaf_findings)}} use-after-free patterns")

    # Phase 5: Deduplicate
    deduped, dup_count = deduplicate_findings(candidates, uaf_findings)

    # Phase 6: Assign IDs
    findings = assign_finding_ids(deduped)

    # Phase 7: Variable renaming analysis
    func_findings = {{}}
    for f in findings:
        func_ea = f.get("analysis", {{}}).get("function_ea", 0)
        if func_ea:
            if func_ea not in func_findings:
                func_findings[func_ea] = []
            func_findings[func_ea].append(f)

    for func_ea, flist in func_findings.items():
        rename_variables_in_function(func_ea, flist)

    # Phase 8: Annotate database
    annotate_database(findings)

    # Generate outputs
    ida_info = {{
        "ida_path": "idat64.exe",
        "log_path": IDA_LOG,
        "exit_code": 0,
        "hexrays_available": HAS_HEXRAYS,
    }}

    results = generate_findings_json(binary_info, findings, functions_scanned, raw_count, dup_count, ida_info)

    with open(FINDINGS_JSON, "w") as f:
        json.dump(results, f, indent=2)
    log(f"[OUTPUT] Wrote findings.json")

    evidence_md = generate_evidence_md(findings, binary_info)
    with open(EVIDENCE_MD, "w") as f:
        f.write(evidence_md)
    log(f"[OUTPUT] Wrote evidence.md")

    pseudocode = generate_pseudocode_export(findings)
    with open(PSEUDOCODE_C, "w") as f:
        f.write(pseudocode)
    log(f"[OUTPUT] Wrote pseudocode.c")

    save_database()

    with open(IDA_LOG, "w") as f:
        f.write("\\n".join(analysis_log))

    log("=" * 70)
    log("ANALYSIS COMPLETE")
    log("=" * 70)
    log(f"Functions scanned: {{functions_scanned}}")
    log(f"Raw candidates: {{raw_count}}")
    log(f"UAF patterns: {{len(uaf_findings)}}")
    log(f"Deduped findings: {{len(findings)}}")
    log(f"Duplicates suppressed: {{dup_count}}")
    log(f"Type/rename changes: {{len(type_changes)}}")
    log(f"Comments written: {{len(comment_sites)}}")
    log("")

    for f in findings:
        ea = f['analysis'].get('call_ea') or f['analysis'].get('use_ea')
        log(f"  [{{f['id']}}] {{f['type']}} @ {{hex(ea) if ea else 'N/A'}}")

    log("")
    log("[STAGE] Exiting IDA")
    idc.qexit(0)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"[FATAL] {{str(e)}}")
        traceback.print_exc()
        idc.qexit(1)
'''

    return script


def run_ida_analysis(
    binary_path: str,
    ida_path: str,
    run_dir: Path,
    windows_temp_dir: str,
    debug: bool = False
) -> dict:
    """Run IDA Pro in batch mode and collect outputs."""

    binary_name = os.path.basename(binary_path)
    run_id = run_dir.name

    # Generate the IDAPython script
    script_content = generate_ida_script(run_id, windows_temp_dir, binary_name)

    # Save script to run directory
    script_path_wsl = run_dir / "ida_script.py"
    with open(script_path_wsl, "w") as f:
        f.write(script_content)

    # Also save to Windows temp for IDA to access
    script_path_windows_wsl = f"{WINDOWS_TEMP_BASE}/{run_id}/ida_script.py"
    os.makedirs(os.path.dirname(script_path_windows_wsl), exist_ok=True)
    shutil.copy(script_path_wsl, script_path_windows_wsl)

    # Convert paths to Windows format
    binary_path_win = wsl_to_windows_path(binary_path)
    script_path_win = wsl_to_windows_path(script_path_windows_wsl)
    log_path_win = wsl_to_windows_path(f"{WINDOWS_TEMP_BASE}/{run_id}/ida_stdout.log")

    # Build command
    cmd = f'"{ida_path}" -A -S"{script_path_win}" -L"{log_path_win}" "{binary_path_win}"'

    # Log command details
    command_info = {
        "command": cmd,
        "ida_path": ida_path,
        "binary_path_wsl": binary_path,
        "binary_path_win": binary_path_win,
        "script_path_wsl": str(script_path_wsl),
        "script_path_win": script_path_win,
        "log_path_win": log_path_win,
        "windows_temp_dir": windows_temp_dir,
    }

    print("\n" + "=" * 70)
    print("IDA BATCH EXECUTION")
    print("=" * 70)
    print(f"Command: {cmd}")
    print(f"\nPath conversions:")
    print(f"  Binary (WSL):   {binary_path}")
    print(f"  Binary (Win):   {binary_path_win}")
    print(f"  Script (WSL):   {script_path_wsl}")
    print(f"  Script (Win):   {script_path_win}")
    print(f"  Output dir:     {windows_temp_dir}")
    print("=" * 70 + "\n")

    # Set environment
    env = os.environ.copy()
    if debug:
        env["IDA_MCP_DEBUG"] = "1"

    # Run IDA
    print("[RUNNING] Starting IDA Pro batch analysis...")
    start_time = datetime.now()

    result = subprocess.run(
        cmd,
        shell=True,
        capture_output=True,
        text=True,
        timeout=600,
        env=env,
    )

    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()

    print(f"[DONE] IDA exited with code {result.returncode} after {duration:.1f}s")

    # Save stdout/stderr
    stdout_stderr_path = run_dir / "ida_stdout_stderr.txt"
    with open(stdout_stderr_path, "w") as f:
        f.write(f"=== IDA BATCH EXECUTION LOG ===\n")
        f.write(f"Command: {cmd}\n")
        f.write(f"Exit code: {result.returncode}\n")
        f.write(f"Duration: {duration:.1f}s\n")
        f.write(f"\n=== STDOUT ===\n")
        f.write(result.stdout or "(empty)")
        f.write(f"\n\n=== STDERR ===\n")
        f.write(result.stderr or "(empty)")

    if result.stdout:
        print("\n--- IDA Output ---")
        lines = result.stdout.split('\n')
        if len(lines) > 100:
            print('\n'.join(lines[:50]))
            print(f"... ({len(lines) - 100} lines omitted) ...")
            print('\n'.join(lines[-50:]))
        else:
            print(result.stdout)
        print("--- End IDA Output ---\n")

    if result.stderr:
        print(f"[STDERR] {result.stderr[:500]}")

    command_info["exit_code"] = result.returncode
    command_info["duration_seconds"] = duration

    return command_info


def collect_artifacts(run_dir: Path, windows_temp_dir_wsl: str) -> dict:
    """Collect artifacts from Windows temp dir to run directory."""

    artifacts = {
        "findings.json": None,
        "evidence.md": None,
        "pseudocode.c": None,
        "ida_batch.log": None,
        "database.i64": None,
    }

    print("\n[COLLECTING] Copying artifacts from Windows temp...")

    for artifact_name in artifacts.keys():
        src = os.path.join(windows_temp_dir_wsl, artifact_name)
        dst = run_dir / artifact_name

        if os.path.exists(src):
            shutil.copy(src, dst)
            size = os.path.getsize(dst)
            print(f"  [OK] {artifact_name} ({size} bytes)")
            artifacts[artifact_name] = str(dst)
        else:
            print(f"  [MISSING] {artifact_name}")

    # Look for .i64 file
    for f in os.listdir(windows_temp_dir_wsl):
        if f.endswith('.i64'):
            src = os.path.join(windows_temp_dir_wsl, f)
            dst = run_dir / "database.i64"
            shutil.copy(src, dst)
            print(f"  [OK] database.i64 (from {f})")
            artifacts["database.i64"] = str(dst)
            break

    return artifacts


def generate_run_summary(
    binary_path: str,
    sha256: str,
    run_dir: Path,
    command_info: dict,
    artifacts: dict,
    findings_data: Optional[dict] = None,
) -> str:
    """Generate the run summary markdown."""

    md = []
    md.append("# Static Analysis Run Summary")
    md.append("")
    md.append(f"**Run ID:** {run_dir.name}")
    md.append(f"**Timestamp:** {datetime.now().isoformat()}")
    md.append(f"**Version:** v2 (Audit Grade)")
    md.append("")
    md.append("## Target Binary")
    md.append("")
    md.append(f"- **Path:** `{binary_path}`")
    md.append(f"- **SHA256:** `{sha256}`")
    md.append("")
    md.append("## IDA Execution Details")
    md.append("")
    md.append("### Command Line (copy-pasteable)")
    md.append("")
    md.append("```bash")
    md.append(command_info["command"])
    md.append("```")
    md.append("")
    md.append("### Path Conversions")
    md.append("")
    md.append("| Resource | WSL Path | Windows Path |")
    md.append("|----------|----------|--------------|")
    md.append(f"| Binary | `{command_info['binary_path_wsl']}` | `{command_info['binary_path_win']}` |")
    md.append(f"| Script | `{command_info['script_path_wsl']}` | `{command_info['script_path_win']}` |")
    md.append(f"| Output | `{command_info['windows_temp_dir']}` | (same) |")
    md.append("")
    md.append("### Execution Results")
    md.append("")
    md.append(f"- **Exit Code:** {command_info['exit_code']}")
    md.append(f"- **Duration:** {command_info.get('duration_seconds', 'N/A')}s")
    md.append("")
    md.append("## Analysis Results")
    md.append("")

    if findings_data:
        analysis = findings_data.get("analysis", {})
        md.append(f"- **Functions Scanned:** {analysis.get('functions_scanned', 'N/A')}")
        md.append(f"- **Raw Candidates:** {analysis.get('raw_candidates', 'N/A')}")
        md.append(f"- **Deduped Findings:** {analysis.get('deduped_findings', 'N/A')}")
        md.append(f"- **Duplicates Suppressed:** {analysis.get('duplicates_suppressed', 'N/A')}")
        md.append(f"- **Hex-Rays Available:** {analysis.get('hexrays_available', 'N/A')}")
        md.append(f"- **Type/Rename Changes:** {analysis.get('type_changes', 0)}")
        md.append("")

        md.append("### Deduplication Strategy")
        md.append("")
        md.append("- **BufferOverflow:** (call_ea, callee_name, dst_type)")
        md.append("- **FormatString:** (call_ea, callee_name)")
        md.append("- **IntegerOverflow:** (malloc_ea, arithmetic_ea) - only emitted if `confidence >= likely`")
        md.append("- **UseAfterFree:** (use_ea, ptr_source) - requires both free AND use evidence")
        md.append("")

        md.append("### Top Findings")
        md.append("")
        md.append("| ID | Type | CWE | Sink | Confidence |")
        md.append("|----|------|-----|------|------------|")

        for f in findings_data.get("findings", [])[:10]:
            fid = f.get("id", "N/A")
            ftype = f.get("type", "N/A")
            cwes = ", ".join(f.get("cwe", []))
            sink = f.get("sink", {})
            sink_str = f"{sink.get('callee', '?')} @ {sink.get('ea', '?')}"
            conf = f.get("confidence", "N/A")
            md.append(f"| {fid} | {ftype} | {cwes} | {sink_str} | {conf} |")

        md.append("")
    else:
        md.append("*No findings data available*")
        md.append("")

    md.append("## Artifacts")
    md.append("")
    md.append("| File | Status | Path |")
    md.append("|------|--------|------|")
    for name, path in artifacts.items():
        status = "OK" if path else "MISSING"
        md.append(f"| {name} | {status} | `{path or 'N/A'}` |")
    md.append("")

    md.append("## Reproduction")
    md.append("")
    md.append("```bash")
    md.append(f"python3 tools/ida_static_analyze.py {binary_path}")
    md.append("```")
    md.append("")

    return "\n".join(md)


def main():
    parser = argparse.ArgumentParser(
        description="Auditable static analysis pipeline using IDA Pro (v2 - Audit Grade)"
    )
    parser.add_argument("binary", help="Path to the binary to analyze")
    parser.add_argument("--ida-path", default=DEFAULT_IDA_PATH, help="Path to IDA Pro executable")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode")
    parser.add_argument("--output-dir", help="Override output directory base")

    args = parser.parse_args()

    if not os.path.isfile(args.binary):
        print(f"[ERROR] Binary not found: {args.binary}")
        sys.exit(1)

    binary_path = os.path.abspath(args.binary)
    binary_name = os.path.basename(binary_path)
    sha256 = compute_sha256(binary_path)

    print(f"\n{'=' * 70}")
    print("IDA STATIC ANALYSIS PIPELINE (v2 - Audit Grade)")
    print(f"{'=' * 70}")
    print(f"Binary: {binary_path}")
    print(f"SHA256: {sha256}")
    print(f"IDA:    {args.ida_path}")
    print(f"Debug:  {args.debug}")

    # Create run directory
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    base_name = os.path.splitext(binary_name)[0]

    if args.output_dir:
        logs_base = Path(args.output_dir)
    else:
        script_dir = Path(__file__).parent.parent
        logs_base = script_dir / "logs"

    run_dir = logs_base / base_name / timestamp
    run_dir.mkdir(parents=True, exist_ok=True)

    print(f"Output: {run_dir}")
    print(f"{'=' * 70}\n")

    # Create Windows temp directory
    windows_temp_dir_wsl = f"{WINDOWS_TEMP_BASE}/{timestamp}"
    os.makedirs(windows_temp_dir_wsl, exist_ok=True)
    windows_temp_dir = wsl_to_windows_path(windows_temp_dir_wsl)

    # Copy binary to Windows temp
    binary_temp = os.path.join(windows_temp_dir_wsl, binary_name)
    shutil.copy(binary_path, binary_temp)

    try:
        command_info = run_ida_analysis(
            binary_temp, args.ida_path, run_dir, windows_temp_dir, args.debug,
        )

        artifacts = collect_artifacts(run_dir, windows_temp_dir_wsl)

        findings_data = None
        if artifacts.get("findings.json"):
            try:
                with open(artifacts["findings.json"]) as f:
                    findings_data = json.load(f)
                findings_data["sha256"] = sha256
                with open(artifacts["findings.json"], "w") as f:
                    json.dump(findings_data, f, indent=2)
            except Exception as e:
                print(f"[WARN] Failed to load findings.json: {e}")

        summary = generate_run_summary(
            binary_path, sha256, run_dir, command_info, artifacts, findings_data,
        )

        summary_path = run_dir / "run_summary.md"
        with open(summary_path, "w") as f:
            f.write(summary)
        print(f"\n[OUTPUT] Wrote run_summary.md")

        print("\n" + "=" * 70)
        print("ANALYSIS COMPLETE")
        print("=" * 70)
        print(f"\nOutputs saved to: {run_dir}")
        print("\nFiles generated:")
        for name in ["run_summary.md", "findings.json", "evidence.md",
                     "ida_script.py", "ida_stdout_stderr.txt", "ida_batch.log",
                     "database.i64", "pseudocode.c"]:
            path = run_dir / name
            if path.exists():
                size = path.stat().st_size
                print(f"  [OK] {name} ({size} bytes)")
            else:
                print(f"  [--] {name} (not generated)")

        if findings_data:
            print(f"\nFindings summary:")
            print(f"  Raw candidates:      {findings_data['analysis'].get('raw_candidates', 0)}")
            print(f"  Deduped findings:    {findings_data['analysis'].get('deduped_findings', 0)}")
            print(f"  Duplicates removed:  {findings_data['analysis'].get('duplicates_suppressed', 0)}")
            print(f"  Type/rename changes: {findings_data['analysis'].get('type_changes', 0)}")

            if findings_data.get("findings"):
                print("\n  Top findings:")
                for f in findings_data["findings"][:5]:
                    sink = f.get("sink", {})
                    print(f"    [{f['id']}] {f['type']} - {sink.get('callee', '?')} @ {sink.get('ea', '?')}")

        print("\n" + "=" * 70 + "\n")
        return 0

    except subprocess.TimeoutExpired:
        print("[ERROR] IDA analysis timed out after 600 seconds")
        return 1
    except Exception as e:
        print(f"[ERROR] Analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
