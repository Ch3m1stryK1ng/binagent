# Introduction
Firmware is a strong target for vulnerability-discovery research because it combines high impact with persistent analysis difficulty. At Internet scale, embedded firmware has repeatedly shown broad and long-lived weaknesses. In practice, source code is often unavailable, updates are slow, and binaries are heterogeneous across architectures/toolchains. Dynamic analysis is often difficult because it depends on firmware rehosting and emulation, where setup and coverage constraints remain substantial. This creates a gap between what is theoretically analyzable and what can be audited reliably under realistic time and compute budgets.

We focus on firmware because it is both security-relevant and a realistic stress case for practical analysis workflows. This is also why firmware is a good LLM target: if dynamic analysis is bottlenecked by rehosting/emulation, then a static-first workflow can create strong value as a triage and hypothesis-generation layer; dynamic confirmation can be optional or targeted. The core problem is firmware vulnerability discovery on binary-only inputs with heterogeneous tool outputs and incomplete context.

LLMs add value here when used as control components, not stand-alone detectors. Compared with traditional static pipelines, an LLM-driven framework can provide: (1) cross-tool orchestration (routing between disassembly, decompilation, xref, and string analyses under one plan), (2) cross-function and cross-binary reasoning (tracking evidence across call chains and binaries instead of isolated function-level checks), (3) semantic hypothesis refinement from pseudocode/assembly context, and (4) evidence-grounded iterative analysis that updates priorities as new facts appear. Recent work supports parts of this direction: stripped-binary semantic recovery (SymGen, VulBinLLM) and tool-mediated planning loops in security agents (e.g., PentestAgent). The main risk is unreliability (hallucination, over-exploration, unstable decisions), which motivates strict execution constraints and direct comparison with non-LLM baselines.

Classical firmware/binary systems provide core primitives (rehosting, symbolic/concolic exploration, fuzzing), but not planner-level resource allocation for long workflows. Concretely, when analysts face `N` binaries, `M` candidate functions, and `K` analysis tools (`decompile`/`xref`/`taint`/`strings`), these systems do not directly optimize which action should be taken next, when to stop, or when to pivot under weak evidence. For firmware static analysis specifically, **Operation Mango** demonstrates strong taint-style vulnerability discovery via scalable static data-flow analysis. Recent LLM-binary papers improve semantic recovery, yet leave open reliability and comparative effectiveness on firmware-scale workflows. Our work is positioned as a reproducible agent-control design evaluated against both LLM-based and traditional analysis baselines.

## Research Questions
1. How can we design and build an LLM-driven framework (BinAgent) that effectively leverages planning, scheduling, and pseudocode-level reasoning to improve firmware binary analysis efficiency and end-to-end vulnerability discovery outcomes?
2. How should we define a benchmark and evaluation protocol that meaningfully characterizes BinAgent's capabilities, limitations, and comparative performance against recent LLM-based systems and traditional static firmware-analysis workflows?

Our working hypothesis is that the main bottleneck is not the lack of standalone analysis primitives, but weak orchestration across existing ones. We therefore design **BinAgent** as an LLM-driven control layer that performs planning, tool routing/scheduling, pseudocode reading, and evidence-grounded synthesis over existing firmware-analysis tools.

These research questions motivate two design principles embedded in the introduction above: first, LLM-orchestrated integration of existing methods (planning, dispatch/scheduling, and pseudocode-guided reasoning) as the mechanism for improvement; second, explicit comparison against traditional workflows to explain where and why LLM-driven orchestration adds measurable value.

## Planned Contributions
1. **BinAgent framework design:** a planner-centric LLM control layer that coordinates existing static-analysis and reverse-engineering tools through plan-act-observe loops, tool scheduling, and pseudocode-guided reasoning.
2. **Integration methodology:** a concrete recipe for combining heterogeneous analysis outputs (disassembly, decompilation, xrefs, strings, and notes) into evidence-linked vulnerability hypotheses and decisions.
3. **Benchmark specification for BinAgent:** a capability-oriented benchmark and protocol covering single-binary and multi-binary firmware tasks, with clear metrics, artifact requirements, and baseline definitions.
